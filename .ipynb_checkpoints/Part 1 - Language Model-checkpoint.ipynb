{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Extraction and Frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus.reader.bnc import BNCCorpusReader\n",
    "from nltk.collocations import *\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.lm import MLE\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "import nltk, re, pprint, string\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "import numpy\n",
    "import random\n",
    "import mpmath as mp\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnc_reader = BNCCorpusReader(root=\"BNC/Texts\", fileids=r'[A-K]/\\w*/\\w*\\.xml')\n",
    "fileids = ['aca/A6U.xml']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_sents = BNCCorpusReader.sents(bnc_reader, fileids=fileids)\n",
    "punct = \"“”‘’!\\\"#$€%&()*'+-,./:;<=>?@[\\]^_`{|}~\\n\"\n",
    "temp = []\n",
    "        \n",
    "for sentence in raw_sents:\n",
    "    temp.append(\"<s>\")\n",
    "    for word in sentence:\n",
    "        if word not in punct:\n",
    "            temp.append(word)\n",
    "    temp.append(\"</s>\")\n",
    "    \n",
    "tokens = [x.lower() for x in temp]\n",
    "# word_list = []\n",
    "# for word in tokens:\n",
    "#     if word is not word_list:\n",
    "#         word_list.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies = []\n",
    "for instance in tokens:\n",
    "    frequencies.append(tokens.count(instance))\n",
    "    \n",
    "word_freq = list(zip(tokens, frequencies))\n",
    "print(word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_words, test_words = train_test_split(tokens, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Language Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vanilla_uni(train_words):\n",
    "    unigram = Counter(train_words)\n",
    "    \n",
    "    for word in unigram:\n",
    "        unigram[word] = unigram[word]/len(train_words)\n",
    "        \n",
    "    return unigram\n",
    "def vanilla_bi(train_words):\n",
    "    bigram = Counter([(word, train_words[i + 1]) for i, word in enumerate(train_words[:-1])])\n",
    "    counter = Counter(train_words)\n",
    "    \n",
    "    for word in bigram:\n",
    "        bigram[word] = bigram[word]/counter[word[0]]\n",
    "        \n",
    "    return bigram\n",
    "    \n",
    "def vanilla_tri(train_words):\n",
    "    bigram = Counter([(word, train_words[i + 1]) for i, word in enumerate(train_words[:-1])])\n",
    "    trigram = Counter([(word, train_words[i + 1], train_words[i + 2]) for i, word in enumerate(train_words[:-2])])\n",
    "    \n",
    "    for word in trigram:\n",
    "        trigram[word] = trigram[word]/bigram[(word[0], word[1])]\n",
    "        \n",
    "    return trigram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laplace Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplace_uni(train_words):\n",
    "    unigram = Counter(train_words)\n",
    "    \n",
    "    for word in unigram:\n",
    "        unigram[word] = unigram[word]+1/len(train_words)\n",
    "        \n",
    "    return unigram\n",
    "def laplace_bi(train_words):\n",
    "    bigram = Counter([(word, train_words[i + 1]) for i, word in enumerate(train_words[:-1])])\n",
    "    counter = Counter(train_words)\n",
    "    \n",
    "    for word in bigram:\n",
    "        bigram[word] = bigram[word]+1/counter[word[0]]\n",
    "        \n",
    "    return bigram\n",
    "    \n",
    "def laplace_tri(train_words):\n",
    "    bigram = Counter([(word, train_words[i + 1]) for i, word in enumerate(train_words[:-1])])\n",
    "    trigram = Counter([(word, train_words[i + 1], train_words[i + 2]) for i, word in enumerate(train_words[:-2])])\n",
    "    \n",
    "    for word in trigram:\n",
    "        trigram[word] = trigram[word]+1/bigram[(word[0], word[1])]\n",
    "        \n",
    "    return trigram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNK Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unk_uni(train_words):\n",
    "    \n",
    "    counter = Counter(train_words)\n",
    "    model = {}\n",
    "    model[\"<UNK>\"] = 0\n",
    "    \n",
    "    for word in counter:\n",
    "        if counter[word] <= 2:\n",
    "            model[\"<UNK>\"] += 1\n",
    "            \n",
    "        else:\n",
    "            model[word] = counter[word]\n",
    "        \n",
    "    return laplace_uni(train_words)\n",
    "\n",
    "def unk_bi(train_words):\n",
    "    \n",
    "    unigram_model = unk_uni(train_words)\n",
    "    \n",
    "    for i, word in enumerate(train_words):\n",
    "        if not (word in unigram_model):\n",
    "            train_words[i] = \"<UNK>\"\n",
    "            \n",
    "    return laplace_bi(train_words)\n",
    "\n",
    "def unk_tri(train_words):\n",
    "    \n",
    "    unigram = unk_uni(train_words)\n",
    "    \n",
    "    for i, word in enumerate(train_words):\n",
    "        if not (word in unigram):\n",
    "            train_words[i] = \"<UNK>\"\n",
    "            \n",
    "    return laplace_tri(train_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uni_prob(model,unigram):\n",
    "    total = sum(model.values())\n",
    "    top = model[unigram]\n",
    "    if top == 0:\n",
    "        return 0\n",
    "    probability = top/total\n",
    "    return probability\n",
    "\n",
    "def bi_prob(model_bi, model_uni, bigram):\n",
    "    first = bigram.split()[0]\n",
    "    second = bigram.split()[1]\n",
    "    total = model_uni[first]\n",
    "    top = model_bi[first,second]\n",
    "    if top == 0:\n",
    "        return 0\n",
    "    if total == 0:\n",
    "        return 0    \n",
    "    probability = top/total\n",
    "    return probability\n",
    "\n",
    "def tri_prob(model_tri, model_bi, trigram):\n",
    "    first = trigram.split()[0]\n",
    "    second = trigram.split()[1]\n",
    "    third = trigram.split()[2]\n",
    "    total = model_bi[second,third]\n",
    "    top = model_tri[first,second,third]\n",
    "    if top == 0:\n",
    "        return 0\n",
    "    if total == 0:\n",
    "        return 0  \n",
    "    probability = top/total\n",
    "    return probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def probability (sentence, model):\n",
    "    sent = \"<s> \"+ sentence + \" </s>\"\n",
    "    words = sent.split()\n",
    "    uni_lambda = 0.1\n",
    "    bi_lambda = 0.3\n",
    "    tri_lambda = 0.6\n",
    "    \n",
    "    unigrams_probability = []\n",
    "    bigrams_probability = []\n",
    "    trigrams_probability = []\n",
    "    \n",
    "    if model == \"Vanilla\":\n",
    "        # unigram\n",
    "                \n",
    "        for word in words:\n",
    "            unigrams_probability.append(uni_prob(vanilla_uni(train_words),word))\n",
    "        \n",
    "        # bigram\n",
    "        \n",
    "        bigrams = nltk.ngrams(words, 2)\n",
    "        for pair in bigrams:\n",
    "            bigram = ' '.join(pair)\n",
    "            bigrams_probability.append(bi_prob(vanilla_bi(train_words), vanilla_uni(train_words), bigram))\n",
    "        \n",
    "        # trigram\n",
    "        trigrams = nltk.ngrams(words, 3)\n",
    "        for trio in trigrams:\n",
    "            trigram = ' '.join(trio)\n",
    "            trigrams_probability.append(tri_prob(vanilla_tri(train_words),vanilla_bi(train_words),trigram))\n",
    "        \n",
    "    elif model == \"Laplace\":\n",
    "        # unigram\n",
    "                \n",
    "        for word in words:\n",
    "            unigrams_probability.append(uni_prob(laplace_uni(train_words),word))\n",
    "        \n",
    "        # bigram\n",
    "        \n",
    "        bigrams = nltk.ngrams(words, 2)\n",
    "        for pair in bigrams:\n",
    "            bigram = ' '.join(pair)\n",
    "            bigrams_probability.append(bi_prob(laplace_bi(train_words), laplace_uni(train_words), bigram))\n",
    "        \n",
    "        # trigram\n",
    "        trigrams = nltk.ngrams(words, 3)\n",
    "        for trio in trigrams:\n",
    "            trigram = ' '.join(trio)\n",
    "            trigrams_probability.append(tri_prob(laplace_tri(train_words),laplace_bi(train_words),trigram))\n",
    "        \n",
    "    elif model == \"UNK\":\n",
    "        # unigram\n",
    "                \n",
    "        for word in words:\n",
    "            unigrams_probability.append(uni_prob(unk_uni(train_words),word))\n",
    "        \n",
    "        \n",
    "        # bigram\n",
    "        \n",
    "        bigrams = nltk.ngrams(words, 2)\n",
    "        for pair in bigrams:\n",
    "            bigram = ' '.join(pair)\n",
    "            bigrams_probability.append(bi_prob(unk_bi(train_words), unk_uni(train_words), bigram))\n",
    "        \n",
    "        # trigram\n",
    "        trigrams = nltk.ngrams(words, 3)\n",
    "        for trio in trigrams:\n",
    "            trigram = ' '.join(trio)\n",
    "            trigrams_probability.append(tri_prob(unk_tri(train_words),unk_bi(train_words),trigram))\n",
    "        \n",
    "    prob1 = numpy.prod(unigrams_probability)\n",
    "    prob2 = numpy.prod(bigrams_probability)\n",
    "    prob3 = numpy.prod(trigrams_probability) \n",
    "    \n",
    "    probability = (uni_lambda*prob1)+(bi_lambda*prob2)+(tri_lambda*prob3)\n",
    "    return probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.452427525511457e-27\n"
     ]
    }
   ],
   "source": [
    "print (probability (\"why does it seem important that the answer\",model=\"UNK\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity(test_words, model):\n",
    "    \n",
    "    p = mp.mpf(1)\n",
    "    \n",
    "    N = mp.mpf(0)\n",
    "    \n",
    "    for line in test_words:\n",
    "        N += len(line)\n",
    "        line = ' '.join(line)\n",
    "        \n",
    "        if model[line] > 0:\n",
    "            p = p * (1/model[line])\n",
    "        else:\n",
    "            p = p * sys.maxsize\n",
    "            \n",
    "    p = pow(p, 1/float(N))\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mpf('7314.567537385079')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity(test_words, vanilla_bi(train_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uni_generate(model, sentence, last = \"\", count = None):\n",
    "    \n",
    "    if(count != 0 and sentence[-1] != last):\n",
    "        \n",
    "        weights = numpy.array(list(model.values()))\n",
    "        norm = weights/numpy.sum(weights)\n",
    "        \n",
    "        resample = numpy.random.multinomial(1, norm)\n",
    "        key = list(resample).index(1)\n",
    "        value = list(model.keys())[key]\n",
    "        \n",
    "        sentence.append(value)\n",
    "        if count != None:\n",
    "            uni_generate(model, sentence, last, count-1)\n",
    "        else:\n",
    "            uni_generate(model, sentence, last)\n",
    "            \n",
    "    return sentence\n",
    "\n",
    "def bi_generate(model, sentence, last, count = None):\n",
    "    if(count != 0 and sentence[-1] != last):\n",
    "        \n",
    "        bigrams = []\n",
    "        b = []\n",
    "        last_word = sentence[-1]\n",
    "        \n",
    "        \n",
    "        for entry in model:\n",
    "            if entry[0] == last_word:\n",
    "                bigrams.append((entry,model[entry]))\n",
    "        if(bigrams == []):\n",
    "            return sentence \n",
    "        \n",
    "        v = [x[1] for x in bigrams]\n",
    "        k = [x[0] for x in bigrams]\n",
    "        weights = numpy.array(v)\n",
    "        norm = weights / numpy.sum(weights)\n",
    "        resample = numpy.random.multinomial(1, norm)\n",
    "        key = list(resample).index(1)\n",
    "        value = k[key]\n",
    "\n",
    "        sentence.append(value[1])\n",
    "\n",
    "        if count != None:\n",
    "            bi_generate(model, sentence, last, count-1)\n",
    "        else:\n",
    "            bi_generate(model, sentence, last)\n",
    "        \n",
    "    return sentence\n",
    "\n",
    "\n",
    "def tri_generate(bi_model, tri_model, sentence, last = \"\", count = None):\n",
    "    if(len(sentence) == 1):\n",
    "        sentence = BigramGenerate(bi_model, sentence, last, count=1)\n",
    "        \n",
    "    if(count != 0 and sentence[-1] != last):\n",
    "        trigrams = []\n",
    "        \n",
    "        for entry in tri_model:\n",
    "            if(entry[0] == sentence[-2] and entry[1] == sentence[-1]):\n",
    "                print(\"yes\")\n",
    "                trigrams[word] = tri_model[word]\n",
    "                \n",
    "        if(trigrams == []):\n",
    "            return sentence\n",
    "        \n",
    "        weights = np.array(list(bigrams.values()))\n",
    "        norm = weights / np.sum(weights)\n",
    "        resample = np.random.multinomial(1, norm)\n",
    "        key = list(resample).index(1)\n",
    "        value = list(bigrams.keys())[key] \n",
    "        \n",
    "        sentence.append(value[2])\n",
    "        if count != None:\n",
    "            tri_generate(bi_model, tri_model, sentence, last, count-1)\n",
    "            \n",
    "        else:\n",
    "            tri_generate(bi_model, tri_model, sentence, last)\n",
    "            \n",
    "            \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating vanilla model...\n",
      "GENERATED VANILLA SENTENCES\n",
      "Trigram: ['<s>', 'when', 'we', 'go']\n"
     ]
    }
   ],
   "source": [
    "model = \"1\"\n",
    "phrase = \"when we go\"\n",
    "\n",
    "if model == \"1\" or model == \"Vanilla\" or model == \"vanilla\":\n",
    "    sent1 = [\"<s>\"]\n",
    "    w = phrase.split()\n",
    "    for word in w:\n",
    "        sent1.append(word)\n",
    "        \n",
    "    sent2 = sent1.copy()\n",
    "    sent3 = sent1.copy()\n",
    "        \n",
    "    print(\"Generating vanilla model...\")\n",
    "    print(\"GENERATED VANILLA SENTENCES\")\n",
    "#     print(\"Unigram: \"+ str (uni_generate(model = vanilla_uni(train_words), sentence = sent1, last = \"</s>\")))\n",
    "#     print(\"Bigram: \"+ str (bi_generate(model = vanilla_bi(train_words), sentence = sent2, last = \"</s>\")))\n",
    "    print(\"Trigram: \"+ str (tri_generate(bi_model = vanilla_bi(train_words), tri_model = vanilla_tri(train_words), sentence = sent3, last = \"</s>\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = input(\"Which model would you like to use? (1) Vanilla (2) Laplace (3) UNK : \")\n",
    "phrase = input(\"Enter phrase to continue to generate: \")\n",
    "generate(model,phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
